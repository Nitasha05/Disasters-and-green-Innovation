{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c66922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import chain\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba20cc4",
   "metadata": {},
   "source": [
    "#### Map file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad06cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdat_patsat_names = {'1_ExTemp':'Extreme temperature ', '3_Storm':'Storm', '4_Flood':'Flood', '5_Landslide':'Landslide', '7_Drought':'Drought', '9_Wildfire':'Wildfire'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff97fd8",
   "metadata": {},
   "source": [
    "#### Map countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f94402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique countries in PATSAT :  148\n"
     ]
    }
   ],
   "source": [
    "countries = []\n",
    "for c in emdat_patsat_names.keys():\n",
    "    df = pd.read_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/' + c + '_panel.csv', skipinitialspace=True, header=0)\n",
    "    countries = countries + pd.unique(df['country']).tolist()\n",
    "patsat_unique_countries = list(set(countries))\n",
    "print(\"# unique countries in PATSAT : \", len(patsat_unique_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a0b00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique countries in EMDAT :  231\n"
     ]
    }
   ],
   "source": [
    "countries = []\n",
    "for c in emdat_patsat_names.values():\n",
    "    df = pd.read_csv('/Volumes/NJ_4TB/EMDAT/'+ c + '_EMDAT_panel.csv', skipinitialspace=True, header=0)\n",
    "    countries = countries + pd.unique(df['country']).tolist()\n",
    "emdat_unique_countries = list(set(countries))\n",
    "print(\"# unique countries in EMDAT : \", len(emdat_unique_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952228bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " 'GI',\n",
       " 'SE',\n",
       " 'AM',\n",
       " 'EP',\n",
       " 'CM',\n",
       " 'SC',\n",
       " 'EG',\n",
       " 'RS',\n",
       " 'CD',\n",
       " 'MY',\n",
       " 'HK',\n",
       " 'LR',\n",
       " 'TJ',\n",
       " 'NZ',\n",
       " 'FO',\n",
       " 'EC',\n",
       " 'AL',\n",
       " 'MO',\n",
       " 'BH',\n",
       " 'HR',\n",
       " 'PH',\n",
       " 'DM',\n",
       " 'ET',\n",
       " 'FI',\n",
       " 'PE',\n",
       " 'BD',\n",
       " 'SI',\n",
       " 'KG',\n",
       " 'LT',\n",
       " 'CU',\n",
       " 'BY',\n",
       " 'CL',\n",
       " 'BB',\n",
       " 'ZA',\n",
       " 'US',\n",
       " 'JP',\n",
       " 'PR',\n",
       " 'BR',\n",
       " 'VE',\n",
       " 'MA',\n",
       " 'ZW',\n",
       " 'BE',\n",
       " 'DZ',\n",
       " 'MG',\n",
       " 'AT',\n",
       " 'NC',\n",
       " 'CO',\n",
       " 'GM',\n",
       " 'AU',\n",
       " 'MT',\n",
       " 'UY',\n",
       " 'NG',\n",
       " 'LB',\n",
       " 'AW',\n",
       " 'CZ',\n",
       " 'BS',\n",
       " 'TN',\n",
       " 'YU',\n",
       " 'CH',\n",
       " 'DD',\n",
       " 'SG',\n",
       " 'JE',\n",
       " 'LK',\n",
       " 'UA',\n",
       " 'CV',\n",
       " 'NP',\n",
       " 'IT',\n",
       " 'MX',\n",
       " 'GR',\n",
       " 'CI',\n",
       " 'PA',\n",
       " 'TW',\n",
       " 'NO',\n",
       " 'RO',\n",
       " 'PT',\n",
       " 'IN',\n",
       " 'GY',\n",
       " 'BG',\n",
       " 'CY',\n",
       " 'PK',\n",
       " 'CS',\n",
       " 'MU',\n",
       " 'TM',\n",
       " 'ST',\n",
       " 'TH',\n",
       " 'CN',\n",
       " 'LU',\n",
       " 'SK',\n",
       " 'GN',\n",
       " 'IL',\n",
       " 'ES',\n",
       " 'MC',\n",
       " 'KY',\n",
       " 'CW',\n",
       " 'TR',\n",
       " 'GE',\n",
       " 'AR',\n",
       " 'AZ',\n",
       " 'BA',\n",
       " 'SR',\n",
       " 'KZ',\n",
       " 'KW',\n",
       " 'JM',\n",
       " 'AE',\n",
       " 'IS',\n",
       " 'IQ',\n",
       " 'MD',\n",
       " 'LV',\n",
       " 'JO',\n",
       " 'KP',\n",
       " 'QA',\n",
       " 'BM',\n",
       " 'EE',\n",
       " 'FR',\n",
       " 'RU',\n",
       " 'BZ',\n",
       " 'CR',\n",
       " 'UZ',\n",
       " 'EA',\n",
       " 'IM',\n",
       " 'DE',\n",
       " 'AG',\n",
       " 'VN',\n",
       " 'SA',\n",
       " 'GB',\n",
       " 'AN',\n",
       " 'CK',\n",
       " 'IE',\n",
       " 'BJ',\n",
       " 'LI',\n",
       " 'KH',\n",
       " 'HU',\n",
       " 'SY',\n",
       " 'GH',\n",
       " 'ID',\n",
       " 'NE',\n",
       " 'AD',\n",
       " 'VG',\n",
       " 'CA',\n",
       " 'PL',\n",
       " 'KR',\n",
       " 'SU',\n",
       " 'NL',\n",
       " 'SN',\n",
       " 'IR',\n",
       " 'SD',\n",
       " 'DK']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patsat_unique_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87f2bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Saudi Arabia']\n"
     ]
    }
   ],
   "source": [
    "r = re.compile(\".*saud\", re.IGNORECASE)\n",
    "print(list(filter(r.match, emdat_unique_countries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb695068",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdat_patsat_countries={ 'KR':'Korea (the Republic of)',\n",
    "                         'MX':'Mexico',\n",
    "                         'EG':'Egypt',\n",
    "                         'JP':'Japan',\n",
    "                         'NO':'Norway',\n",
    "                         'CA':'Canada',\n",
    "                         'SI':'Slovenia',\n",
    "                         'DK':'Denmark',\n",
    "                         'TH':'Thailand',\n",
    "                         'FI':'Finland',\n",
    "                         'HU':'Hungary',\n",
    "                         'IS':'Iceland',\n",
    "                         'IN':'India',\n",
    "                         'US':'United States of America (the)',\n",
    "                         'CZ':['Czech Republic (the)', 'Czechoslovakia','Slovakia'],\n",
    "                         'CL':'Chile',\n",
    "                         'PL':'Poland',\n",
    "                         'LV':'Latvia',\n",
    "                         'KY':'Cayman Islands (the)',\n",
    "                         'PH':'Philippines (the)',\n",
    "                         'DE':['Germany Dem Rep', 'Germany', 'Germany Fed Rep'],#also DD\n",
    "                         'SG':'Singapore',\n",
    "                         'CH':'Switzerland',\n",
    "                         'LT':'Lithuania',\n",
    "                         'CY':'Cyprus',\n",
    "                         'RU':'Russian Federation (the)',\n",
    "                         'UA':'Ukraine',\n",
    "                         'IT':'Italy',\n",
    "                         'AU':'Australia',\n",
    "                         'NZ':'New Zealand',\n",
    "                         'BE':'Belgium',\n",
    "                         'QA':'Qatar',\n",
    "                         'MY':'Malaysia',\n",
    "                         'BM':'Bermuda',\n",
    "                         'AT':'Austria',\n",
    "                         'SU':'Soviet Union',\n",
    "                         'GR':'Greece',\n",
    "                         'MT':'Malta',\n",
    "                         'IE':'Ireland',\n",
    "                         'TR':'Turkey',\n",
    "                         'ES':'Spain',\n",
    "                         'NL':'Netherlands (the)',\n",
    "                         'IL':'Israel',\n",
    "                         'MA':'Morocco',\n",
    "                         'AE':'United Arab Emirates (the)',\n",
    "                         'CU':'Cuba',\n",
    "                         'SE':'Sweden',\n",
    "                         'CN':'China',\n",
    "                         'FR':'France',\n",
    "                         'LU':'Luxembourg',\n",
    "                         'PA':'Panama',\n",
    "                         'BG':'Bulgaria',\n",
    "                         'ZA':'South Africa',\n",
    "                         'TW':'Taiwan (Province of China)',\n",
    "                         'AR':'Argentina',\n",
    "                         'BR':'Brazil',\n",
    "                         'GB':'United Kingdom of Great Britain and Northern Ireland (the)',\n",
    "                         'SA':'Saudi Arabia'\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9764418e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Korea (the Republic of)': 'KR',\n",
       " 'Mexico': 'MX',\n",
       " 'Egypt': 'EG',\n",
       " 'Japan': 'JP',\n",
       " 'Norway': 'NO',\n",
       " 'Canada': 'CA',\n",
       " 'Slovenia': 'SI',\n",
       " 'Denmark': 'DK',\n",
       " 'Thailand': 'TH',\n",
       " 'Finland': 'FI',\n",
       " 'Hungary': 'HU',\n",
       " 'Iceland': 'IS',\n",
       " 'India': 'IN',\n",
       " 'United States of America (the)': 'US',\n",
       " 'Czech Republic (the)': 'CZ0',\n",
       " 'Czechoslovakia': 'CZ1',\n",
       " 'Slovakia': 'CZ2',\n",
       " 'Chile': 'CL',\n",
       " 'Poland': 'PL',\n",
       " 'Latvia': 'LV',\n",
       " 'Cayman Islands (the)': 'KY',\n",
       " 'Philippines (the)': 'PH',\n",
       " 'Germany Dem Rep': 'DE0',\n",
       " 'Germany': 'DE1',\n",
       " 'Germany Fed Rep': 'DE2',\n",
       " 'Singapore': 'SG',\n",
       " 'Switzerland': 'CH',\n",
       " 'Lithuania': 'LT',\n",
       " 'Cyprus': 'CY',\n",
       " 'Russian Federation (the)': 'RU',\n",
       " 'Ukraine': 'UA',\n",
       " 'Italy': 'IT',\n",
       " 'Australia': 'AU',\n",
       " 'New Zealand': 'NZ',\n",
       " 'Belgium': 'BE',\n",
       " 'Qatar': 'QA',\n",
       " 'Malaysia': 'MY',\n",
       " 'Bermuda': 'BM',\n",
       " 'Austria': 'AT',\n",
       " 'Soviet Union': 'SU',\n",
       " 'Greece': 'GR',\n",
       " 'Malta': 'MT',\n",
       " 'Ireland': 'IE',\n",
       " 'Turkey': 'TR',\n",
       " 'Spain': 'ES',\n",
       " 'Netherlands (the)': 'NL',\n",
       " 'Israel': 'IL',\n",
       " 'Morocco': 'MA',\n",
       " 'United Arab Emirates (the)': 'AE',\n",
       " 'Cuba': 'CU',\n",
       " 'Sweden': 'SE',\n",
       " 'China': 'CN',\n",
       " 'France': 'FR',\n",
       " 'Luxembourg': 'LU',\n",
       " 'Panama': 'PA',\n",
       " 'Bulgaria': 'BG',\n",
       " 'South Africa': 'ZA',\n",
       " 'Taiwan (Province of China)': 'TW',\n",
       " 'Argentina': 'AR',\n",
       " 'Brazil': 'BR',\n",
       " 'United Kingdom of Great Britain and Northern Ireland (the)': 'GB',\n",
       " 'Saudi Arabia': 'SA'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emdat_patsat_map = {}\n",
    "for key, val in emdat_patsat_countries.items():\n",
    "    if key == 'CZ' or key == 'DE':\n",
    "        for i, coun in enumerate(val):\n",
    "            emdat_patsat_map[coun] = key + str(i)\n",
    "    else:\n",
    "        emdat_patsat_map[val] = key\n",
    "emdat_patsat_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be34ab8",
   "metadata": {},
   "source": [
    "### Combine PATSAT, EMDAT\n",
    "#### also, combine DE and DD in PATSAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb995ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for patsat, emdat in emdat_patsat_names.items():\n",
    "#     df_patsat =  pd.read_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/' + patsat + '_panel.csv', skipinitialspace=True, header=0)\n",
    "#     df_emdat = pd.read_csv(emdat + '_EMDAT_panel.csv', skipinitialspace=True, header=0)\n",
    "#     ## combine DE with DD\n",
    "#     if np.where(df_patsat['country'] == 'DD')[0].size>0:\n",
    "#         for year in range( 1985,  2020 + 1):\n",
    "#             dd_year = np.where((df_patsat['year'] == year) & (df_patsat['country'] == 'DD'))\n",
    "#             if dd_year[0].size>0:\n",
    "#                 dd = dd_year[0][0]\n",
    "#                 de = np.where((df_patsat['year'] == year) & (df_patsat['country'] == 'DE') )[0][0]\n",
    "#                 df_patsat.at[de,'total_count'] += df_patsat.at[dd,'total_count']\n",
    "#                 df_patsat.at[de,'granted_count'] +=  df_patsat.at[dd,'granted_count']\n",
    "#                 df_patsat.at[de,'granted_family_ge_2_count'] += df_patsat.at[dd,'granted_family_ge_2_count']\n",
    "#     df_patsat.drop(df_patsat[df_patsat['country'] == 'LI'].index, inplace=True)\n",
    "#     df_patsat.drop(df_patsat[df_patsat['country'] == 'VG'].index, inplace=True)\n",
    "#     df_patsat.drop(df_patsat[df_patsat['country'] == 'DD'].index, inplace=True)\n",
    "#     df_patsat.drop(df_patsat[df_patsat['country'] == 'FO'].index, inplace=True)\n",
    "#     df_patsat[\"total_deaths\"] = 0\n",
    "#     df_patsat[\"total_affected\"] = 0\n",
    "#     df_patsat[\"total_damages_adj\"] = 0\n",
    "#     for country in pd.unique(df_patsat.country):\n",
    "#         if country == 'DE' or country == 'CZ':\n",
    "#             emdat_countries = emdat_patsat_countries[country]\n",
    "#         else:\n",
    "#             emdat_countries = [emdat_patsat_countries[country]]\n",
    "        \n",
    "#         for ec in emdat_countries:\n",
    "#             for year in range( 1985,  2020 + 1):\n",
    "#                 pt_year = np.where((df_patsat['year'] == year) & (df_patsat['country'] == country))\n",
    "#                 if pt_year[0].size>0:\n",
    "#                     pt = pt_year[0][0]\n",
    "#                     em = np.where((df_emdat['year'] == year) & (df_emdat['country'] == ec) )[0][0]\n",
    "#                     df_patsat.at[pt,'total_deaths'] = df_emdat.at[em,'total_deaths']\n",
    "#                     df_patsat.at[pt,'total_affected'] =  df_emdat.at[em,'total_affected']\n",
    "#                     df_patsat.at[pt,'total_damages_adj'] = df_emdat.at[em,'total_damages_adj']\n",
    "#     if patsat=='1_ExTemp':\n",
    "#         print(pd.unique(df_patsat['country']))\n",
    "        \n",
    "#     print('Combined ' + patsat)    \n",
    "#     df_patsat.to_csv(patsat + '_panel_combined.csv', encoding='utf-8', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7178e135",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 1_ExTemp\n",
      "Combined 3_Storm\n",
      "Combined 4_Flood\n",
      "Combined 5_Landslide\n",
      "Combined 7_Drought\n",
      "Combined 9_Wildfire\n"
     ]
    }
   ],
   "source": [
    "for patsat, emdat in emdat_patsat_names.items():\n",
    "    df_patsat =  pd.read_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/' + patsat + '_panel.csv', skipinitialspace=True, header=0)\n",
    "    df_emdat = pd.read_csv('/Volumes/NJ_4TB/EMDAT/' + emdat + '_EMDAT_panel.csv', skipinitialspace=True, header=0)\n",
    "    if np.where(df_patsat['country'] == 'DD')[0].size>0:\n",
    "        for year in range( 1985,  2020 + 1):\n",
    "            dd_year = np.where((df_patsat['year'] == year) & (df_patsat['country'] == 'DD'))\n",
    "            if dd_year[0].size>0:\n",
    "                dd = dd_year[0][0]\n",
    "                de = np.where((df_patsat['year'] == year) & (df_patsat['country'] == 'DE') )[0][0]\n",
    "                df_patsat.at[de,'total_count'] += df_patsat.at[dd,'total_count']\n",
    "                df_patsat.at[de,'granted_count'] +=  df_patsat.at[dd,'granted_count']\n",
    "                df_patsat.at[de,'granted_family_ge_2_count'] += df_patsat.at[dd,'granted_family_ge_2_count']\n",
    "                df_patsat.at[de,'K_stock'] += df_patsat.at[dd,'K_stock']\n",
    "    df_patsat.drop(df_patsat[df_patsat['country'] == 'LI'].index, inplace=True)\n",
    "    df_patsat.drop(df_patsat[df_patsat['country'] == 'VG'].index, inplace=True)\n",
    "    df_patsat.drop(df_patsat[df_patsat['country'] == 'DD'].index, inplace=True)\n",
    "    df_patsat.drop(df_patsat[df_patsat['country'] == 'FO'].index, inplace=True)\n",
    "    df_emdat['country'] = df_emdat['country'].map(emdat_patsat_map).fillna(df_emdat['country'])\n",
    "    list_columns=df_emdat.columns.to_list()\n",
    "    list_columns.remove('year')\n",
    "    list_columns.remove('country')\n",
    "    df_de = df_emdat[df_emdat['country']=='DE0'][list_columns].reset_index().drop(columns=['index']) + df_emdat[df_emdat['country']=='DE1'][list_columns].reset_index().drop(columns=['index']) + df_emdat[df_emdat['country']=='DE2'][list_columns].reset_index().drop(columns=['index'])\n",
    "    df_de['country']='DE'\n",
    "    df_de['year']=df_emdat[df_emdat['country']=='DE0']['year'].reset_index().drop(columns=['index'])\n",
    "    df_de.drop(0,inplace=True)\n",
    "\n",
    "    df_cz = df_emdat[df_emdat['country']=='CZ0'][list_columns].reset_index().drop(columns=['index']) + df_emdat[df_emdat['country']=='CZ1'][list_columns].reset_index().drop(columns=['index']) + df_emdat[df_emdat['country']=='CZ2'][list_columns].reset_index().drop(columns=['index'])\n",
    "    df_cz['country']='CZ'\n",
    "    df_cz['year']=df_emdat[df_emdat['country']=='CZ0']['year'].reset_index().drop(columns=['index'])\n",
    "    df_cz.drop(0,inplace=True)\n",
    "    df_emdat = pd.concat([df_de,df_cz,df_emdat])\n",
    "    df_combined = df_patsat.merge(df_emdat,on=['country','year'], how='inner')\n",
    "    df_combined.to_csv('/Volumes/NJ_4TB/Final/' + patsat + '_panel_combined.csv', encoding='utf-8', index=False)\n",
    "    print('Combined ' + patsat)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05977a53",
   "metadata": {},
   "source": [
    "### Combine green technologies PATSAT data with the combined data above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa12984a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing: Build\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitashajhala/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing: Sequester\n",
      "Now processing: ICT\n",
      "Now processing: Geo\n",
      "Now processing: Hydro\n",
      "Now processing: Ocean\n",
      "Now processing: Solar-T\n",
      "Now processing: PV\n",
      "Now processing: Thermal-PV\n",
      "Now processing: Wind\n",
      "Now processing: Combust\n",
      "Now processing: Fusion\n",
      "Now processing: Fission\n",
      "Now processing: Electric\n",
      "Now processing: Biofuel\n",
      "Now processing: Waste\n",
      "Now processing: Store- B\n",
      "Now processing: Store - C\n",
      "Now processing: Store- T\n",
      "Now processing: Store- M\n",
      "Now processing: Hydrogen\n",
      "Now processing: Processing\n",
      "Now processing: Transport\n",
      "Now processing: Wastewater\n",
      "Now processing: SmrtGrds\n",
      "Now processing: Nuclear\n",
      "Now processing: Non-Fossil\n",
      "Now processing: Enable\n",
      "Now processing: Other-1\n",
      "Now processing: Other-3\n",
      "Now processing: Other-4\n"
     ]
    }
   ],
   "source": [
    "Categories = ['Build','Sequester', 'ICT', 'Geo', 'Hydro', 'Ocean', 'Solar-T', 'PV', 'Thermal-PV', 'Wind', 'Combust', 'Fusion', 'Fission', 'Electric', 'Biofuel', 'Waste', 'Store- B', 'Store - C', 'Store- T', 'Store- M', 'Hydrogen', 'Processing', 'Transport', 'Wastewater', 'SmrtGrds', 'Nuclear', 'Non-Fossil', 'Enable',  'Other-1', 'Other-3', 'Other-4']#,'Other-6', 'Other-5']\n",
    "#Categories = ['Other-4','Other-5', 'Other-6']\n",
    "df_controls =pd.read_csv('/Volumes/NJ_4TB/Final/controls_processed.csv', skipinitialspace=True, header=0)\n",
    "for category in Categories:\n",
    "    print(\"Now processing: \"+ category)\n",
    "    try:\n",
    "        df_cat = pd.read_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/' + category + '_panel.csv', skipinitialspace=True, header=0)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        df_cat = pd.DataFrame()\n",
    "    if df_cat.empty:\n",
    "        print('Skipped '+ category)\n",
    "        continue\n",
    "    if np.where(df_cat['country'] == 'DD')[0].size>0:\n",
    "        for year in range( 1985,  2020 + 1):\n",
    "            dd_year = np.where((df_cat['year'] == year) & (df_cat['country'] == 'DD'))\n",
    "            if dd_year[0].size>0:\n",
    "                dd = dd_year[0][0]\n",
    "                de = np.where((df_cat['year'] == year) & (df_cat['country'] == 'DE') )[0][0]\n",
    "                df_cat.at[de,'total_count'] += df_cat.at[dd,'total_count']\n",
    "                df_cat.at[de,'granted_count'] +=  df_cat.at[dd,'granted_count']\n",
    "                df_cat.at[de,'granted_family_ge_2_count'] += df_cat.at[dd,'granted_family_ge_2_count']\n",
    "                df_cat.at[de,'K_stock'] += df_cat.at[dd,'K_stock']\n",
    "    df_cat.drop(df_cat[df_cat['country'] == 'LI'].index, inplace=True)\n",
    "    df_cat.drop(df_cat[df_cat['country'] == 'VG'].index, inplace=True)\n",
    "    df_cat.drop(df_cat[df_cat['country'] == 'DD'].index, inplace=True)\n",
    "    df_cat.drop(df_cat[df_cat['country'] == 'FO'].index, inplace=True)\n",
    "    df_cat = pd.concat([pd.get_dummies(df_cat['year']), df_cat],axis=1)\n",
    "    df_cat.loc[:, 'K_stock'] = np.log(1 + df_cat['K_stock'])\n",
    "    df_cat.rename(columns={'total_count':category+'_total_count', 'granted_count':category +'_granted_count', 'granted_family_ge_2_count':category+'_granted_family_ge_2_count', 'K_stock':category+'_K_stock'}, inplace=True)\n",
    "    df_cat = df_cat.merge(df_controls, on=['country','year'], how='left')#NaNs if controls are not present \n",
    "    for adaptive in emdat_patsat_names.keys():        \n",
    "        df_adapt = pd.read_csv('/Volumes/NJ_4TB/Final/' + adaptive + '_panel_combined.csv', skipinitialspace=True, header=0)\n",
    "        df_adapt.loc[:, 'K_stock'] = np.log(1 + df_adapt['K_stock'])\n",
    "        df_adapt.rename(columns={'total_count':adaptive+'_total_count', 'granted_count':adaptive+'_granted_count', 'granted_family_ge_2_count':adaptive+'_granted_family_ge_2_count', 'K_stock':adaptive+'_K_stock'}, inplace=True)\n",
    "        df_final=df_cat.merge(df_adapt, on=['country','year'], how='inner')\n",
    "        df_final.loc[:, 'gdp_per_capita'] = np.log(df_final['gdp_per_capita'])\n",
    "        df_final.loc[:, 'control_total_patents'] = np.log(df_final['control_total_patents'])\n",
    "        df_final.drop(df_final[df_final['year'] >2018].index, inplace=True)\n",
    "        df_final.drop(labels =2019, axis =1, inplace=True, errors='ignore')\n",
    "        df_final.drop(labels =2020, axis =1, inplace=True, errors='ignore')\n",
    "        #  print('Combined ' + category + ' with '+ adaptive)    \n",
    "        directory = '/Volumes/NJ_4TB/Final/Adaptive_Mitigative/'# + category + '_' + adaptive + '/'\n",
    "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "        df_final.to_csv( directory + category + '_' + adaptive + '_panel_combined.csv', encoding='utf-8', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/Other-6_panel.csv', skipinitialspace=True, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05249e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting chosen country samples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "Categories = ['Build','Sequester', 'ICT', 'Geo', 'Hydro', 'Ocean', 'Solar-T', 'PV', 'Thermal-PV', 'Wind', 'Combust', 'Fusion', 'Fission', 'Electric', 'Biofuel', 'Waste', 'Store- B', 'Store - C', 'Store- T', 'Store- M', 'Hydrogen', 'Processing', 'Transport', 'Wastewater', 'SmrtGrds', 'Nuclear', 'Non-Fossil', 'Enable',  'Other-1', 'Other-3']#, 'Other-5','Other-6', 'Other-4']\n",
    "emdat_patsat_names = {'1_ExTemp':'Extreme temperature ', '3_Storm':'Storm', '4_Flood':'Flood', '5_Landslide':'Landslide', '7_Drought':'Drought', '9_Wildfire':'Wildfire'}\n",
    "countries = {'Country': ['KR','MX','EG','JP','NO','CA','SI','DK','TH','FI','HU','IS','IN','US','CZ','CL','PL','LV','KY','PH','DE','SG','CH','LT', 'CY',                          \n",
    "'RU','UA','IT','AU','NZ','BE','QA','MY','BM','AT','SU','GR','MT','IE','TR','ES','NL','IL','MA','AE','CU', 'SE',                          \n",
    "'CN','FR','LU','PA','BG','ZA','TW','AR','BR','GB','SA']}                         \n",
    "sample_list = pd.DataFrame(countries)\n",
    "for a in emdat_patsat_names:\n",
    "    for c in Categories:\n",
    "        df = pd.read_csv('/Volumes/NJ_4TB/Final/Adaptive_Mitigative/'+ c + '_'+ a + '_panel_combined.csv', skipinitialspace=True, header=0)\n",
    "        sample = pd.Series(df['country'].unique())\n",
    "        sample_list[c + '_' + a] = sample_list.iloc[:, 0].isin(sample)\n",
    "sample_list.to_csv('/Volumes/NJ_4TB/Final/Adaptive_Mitigative/sample_list.csv', index=False)\n",
    "sample_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Sample by Country\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "Categories = ['Build','Sequester', 'ICT', 'Geo', 'Hydro', 'Ocean', 'Solar-T', 'PV', 'Thermal-PV', 'Wind', 'Combust', 'Fusion', 'Fission', 'Electric', 'Biofuel', 'Waste', 'Store- B', 'Store - C', 'Store- T', 'Store- M', 'Hydrogen', 'Processing', 'Transport', 'Wastewater', 'SmrtGrds', 'Nuclear', 'Non-Fossil', 'Enable',  'Other-1', 'Other-3']#, 'Other-5','Other-6', 'Other-4']\n",
    "emdat_patsat_names = {'1_ExTemp':'Extreme temperature ', '3_Storm':'Storm', '4_Flood':'Flood', '5_Landslide':'Landslide', '7_Drought':'Drought', '9_Wildfire':'Wildfire'}\n",
    "#countries = {'KR', 'JP', 'NO', 'CA', 'DK', 'HU', 'IN', 'US', 'DE', 'CH', 'RU', 'IT', 'AU', 'BE', 'AT', 'ES', 'NL', 'IL', 'SE', 'CN', 'FR', 'TW', 'BR', 'GB'}\n",
    "for a in emdat_patsat_names:\n",
    "    for c in Categories:\n",
    "        df = pd.read_csv('/Volumes/NJ_4TB/Final/Adaptive_Mitigative/'+ c + '_'+ a + '_panel_combined.csv', skipinitialspace=True, header=0)\n",
    "        df = df[df['country'].str.contains('(KR|JP|NO|CA|DK|HU|IN|US|DE|CH|RU|IT|AU|BE|AT|ES|NL|IL|SE|CN|FR|TW|BR|GB)', regex=True)]\n",
    "        df.to_csv('/Volumes/NJ_4TB/Final/Adaptive_Mitigative/'+ c + '_'+ a + '_panel_24countries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fddc4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
