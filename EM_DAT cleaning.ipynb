{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d562eebd",
   "metadata": {},
   "source": [
    "### different disasters = different datasets\n",
    "### each dataset = by country and year\n",
    "### country, year, total people affected, total deaths, total damages in usd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9db20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daafe4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10080/1074600298.py:1: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv('EMDAT.csv', skipinitialspace=True, skiprows=6)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('EMDAT.csv', skipinitialspace=True, skiprows=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5dbfaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Disaster types:  18\n",
      "# Countries :  231\n"
     ]
    }
   ],
   "source": [
    "disasters = pd.unique(df1['Disaster Type'])\n",
    "countries = pd.unique(df1['Country'])\n",
    "print('# Disaster types: ', len(disasters) )\n",
    "print('# Countries : ', len(countries) )\n",
    "#NaNs in interested columns tobe considered 0\n",
    "df1['Total Deaths'].fillna(0, inplace = True)\n",
    "df1['Total Affected'].fillna(0, inplace = True)\n",
    "df1[\"Total Damages, Adjusted ('000 US$)\"].fillna(0, inplace = True)\n",
    "start_year = 1985\n",
    "end_year = 2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d05da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing disaster:  Storm\n",
      "Processing disaster:  Earthquake\n",
      "Processing disaster:  Landslide\n",
      "Processing disaster:  Flood\n",
      "Processing disaster:  Wildfire\n",
      "Processing disaster:  Epidemic\n",
      "Processing disaster:  Transport accident\n",
      "Processing disaster:  Industrial accident\n",
      "Processing disaster:  Miscellaneous accident\n",
      "Processing disaster:  Drought\n",
      "Processing disaster:  Volcanic activity\n",
      "Processing disaster:  Extreme temperature \n",
      "Processing disaster:  Insect infestation\n",
      "Processing disaster:  Mass movement (dry)\n",
      "Processing disaster:  Complex Disasters\n",
      "Processing disaster:  Impact\n",
      "Processing disaster:  Animal accident\n",
      "Processing disaster:  Glacial lake outburst\n"
     ]
    }
   ],
   "source": [
    "for disaster in disasters:    \n",
    "    print(\"Processing disaster: \", disaster)\n",
    "    disaster_all_dataframes = []\n",
    "    for country in countries:\n",
    "        sub_index = (df1['Country'] == country) & (df1['Disaster Type'] == disaster)\n",
    "        single_year_events = sub_index & (df1['End Year'] == df1['Start Year'])\n",
    "        multi_year_events = np.where(sub_index & (df1['End Year'] != df1['Start Year']))[0]\n",
    "        list_of_points = []\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            indices = single_year_events & (df1['Year'] == year)\n",
    "            total_deaths = sum(df1['Total Deaths'][indices])\n",
    "            total_affected = sum(df1['Total Affected'][indices])\n",
    "            total_damages_adj = sum(df1[\"Total Damages, Adjusted ('000 US$)\"][indices])\n",
    "            list_of_points.append({'country':country, 'year':year, 'total_deaths':total_deaths, 'total_affected':total_affected, 'total_damages_adj':total_damages_adj})\n",
    "        disaster_df = pd.DataFrame.from_records(list_of_points)\n",
    "        for event in multi_year_events:\n",
    "            n_years = df1.iloc[event]['End Year'] - df1.iloc[event]['Start Year'] + 1.0\n",
    "            damage = df1.iloc[event][\"Total Damages, Adjusted ('000 US$)\"].copy() / n_years\n",
    "            affected = df1.iloc[event][\"Total Affected\"] / n_years\n",
    "            deaths = df1.iloc[event][\"Total Deaths\"] / n_years\n",
    "            for year in range( df1.iloc[event]['Start Year'],  df1.iloc[event]['End Year'] + 1):\n",
    "                if np.where(disaster_df['year'] == year)[0].size>0:\n",
    "                    r = np.where(disaster_df['year'] == year)[0][0]\n",
    "                    disaster_df.at[r,'total_deaths'] += deaths\n",
    "                    disaster_df.at[r,'total_affected'] +=  affected\n",
    "                    disaster_df.at[r,'total_damages_adj'] += damage\n",
    "        disaster_all_dataframes.append(disaster_df)\n",
    "    disaster_all_countries = pd.concat(disaster_all_dataframes)\n",
    "#     disaster_all_countries.to_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/' + disaster + '_EMDAT_panel.csv', encoding='utf-8', index=False) \n",
    "    disaster_all_countries.to_csv(disaster + '_EMDAT_panel.csv', encoding='utf-8', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b6860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
