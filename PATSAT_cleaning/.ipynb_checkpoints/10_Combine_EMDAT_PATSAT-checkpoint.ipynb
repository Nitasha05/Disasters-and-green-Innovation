{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c66922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import chain\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba20cc4",
   "metadata": {},
   "source": [
    "#### Map file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdat_patsat_names = {'1_ExTemp':'Extreme temperature ', '3_Storm':'Storm', '4_Flood':'Flood', '5_Landslide':'Landslide', '7_Drought':'Drought', '9_Wildfire':'Wildfire'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff97fd8",
   "metadata": {},
   "source": [
    "#### Map countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f94402",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = []\n",
    "for c in emdat_patsat_names.keys():\n",
    "    df = pd.read_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/' + c + '_panel.csv', skipinitialspace=True, header=0)\n",
    "    countries = countries + pd.unique(df['country']).tolist()\n",
    "patsat_unique_countries = list(set(countries))\n",
    "print(\"# unique countries in PATSAT : \", len(patsat_unique_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = []\n",
    "for c in emdat_patsat_names.values():\n",
    "    df = pd.read_csv(c + '_EMDAT_panel.csv', skipinitialspace=True, header=0)\n",
    "    countries = countries + pd.unique(df['country']).tolist()\n",
    "emdat_unique_countries = list(set(countries))\n",
    "print(\"# unique countries in EMDAT : \", len(emdat_unique_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952228bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patsat_unique_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\".*saud\", re.IGNORECASE)\n",
    "print(list(filter(r.match, emdat_unique_countries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb695068",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdat_patsat_countries={ 'KR':'Korea (the Republic of)',\n",
    "                         'MX':'Mexico',\n",
    "                         'EG':'Egypt',\n",
    "                         'JP':'Japan',\n",
    "                         'NO':'Norway',\n",
    "                         'CA':'Canada',\n",
    "                         'SI':'Slovenia',\n",
    "                         'DK':'Denmark',\n",
    "                         'TH':'Thailand',\n",
    "                         'FI':'Finland',\n",
    "                         'HU':'Hungary',\n",
    "                         'IS':'Iceland',\n",
    "                         'IN':'India',\n",
    "                         'US':'United States of America (the)',\n",
    "                         'CZ':['Czech Republic (the)', 'Czechoslovakia','Slovakia'],\n",
    "                         'CL':'Chile',\n",
    "                         'PL':'Poland',\n",
    "                         'LV':'Latvia',\n",
    "                         'KY':'Cayman Islands (the)',\n",
    "                         'PH':'Philippines (the)',\n",
    "                         'DE':['Germany Dem Rep', 'Germany', 'Germany Fed Rep'],#also DD\n",
    "                         'SG':'Singapore',\n",
    "                         'CH':'Switzerland',\n",
    "                         'LT':'Lithuania',\n",
    "                         'CY':'Cyprus',\n",
    "                         'RU':'Russian Federation (the)',\n",
    "                         'UA':'Ukraine',\n",
    "                         'IT':'Italy',\n",
    "                         'AU':'Australia',\n",
    "                         'NZ':'New Zealand',\n",
    "                         'BE':'Belgium',\n",
    "                         'QA':'Qatar',\n",
    "                         'MY':'Malaysia',\n",
    "                         'BM':'Bermuda',\n",
    "                         'AT':'Austria',\n",
    "                         'SU':'Soviet Union',\n",
    "                         'GR':'Greece',\n",
    "                         'MT':'Malta',\n",
    "                         'IE':'Ireland',\n",
    "                         'TR':'Turkey',\n",
    "                         'ES':'Spain',\n",
    "                         'NL':'Netherlands (the)',\n",
    "                         'IL':'Israel',\n",
    "                         'MA':'Morocco',\n",
    "                         'AE':'United Arab Emirates (the)',\n",
    "                         'CU':'Cuba',\n",
    "                         'SE':'Sweden',\n",
    "                         'CN':'China',\n",
    "                         'FR':'France',\n",
    "                         'LU':'Luxembourg',\n",
    "                         'PA':'Panama',\n",
    "                         'BG':'Bulgaria',\n",
    "                         'ZA':'South Africa',\n",
    "                         'TW':'Taiwan (Province of China)',\n",
    "                         'AR':'Argentina',\n",
    "                         'BR':'Brazil',\n",
    "                         'GB':'United Kingdom of Great Britain and Northern Ireland (the)',\n",
    "                         'SA':'Saudi Arabia'\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764418e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emdat_patsat_map = {}\n",
    "for key, val in emdat_patsat_countries.items():\n",
    "    if key == 'CZ' or key == 'DE':\n",
    "        for i, coun in enumerate(val):\n",
    "            emdat_patsat_map[coun] = key + str(i)\n",
    "    else:\n",
    "        emdat_patsat_map[val] = key\n",
    "emdat_patsat_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be34ab8",
   "metadata": {},
   "source": [
    "### Combine PATSAT, EMDAT\n",
    "#### also, combine DE and DD in PATSAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb995ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for patsat, emdat in emdat_patsat_names.items():\n",
    "#     df_patsat =  pd.read_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/' + patsat + '_panel.csv', skipinitialspace=True, header=0)\n",
    "#     df_emdat = pd.read_csv(emdat + '_EMDAT_panel.csv', skipinitialspace=True, header=0)\n",
    "#     ## combine DE with DD\n",
    "#     if np.where(df_patsat['country'] == 'DD')[0].size>0:\n",
    "#         for year in range( 1985,  2020 + 1):\n",
    "#             dd_year = np.where((df_patsat['year'] == year) & (df_patsat['country'] == 'DD'))\n",
    "#             if dd_year[0].size>0:\n",
    "#                 dd = dd_year[0][0]\n",
    "#                 de = np.where((df_patsat['year'] == year) & (df_patsat['country'] == 'DE') )[0][0]\n",
    "#                 df_patsat.at[de,'total_count'] += df_patsat.at[dd,'total_count']\n",
    "#                 df_patsat.at[de,'granted_count'] +=  df_patsat.at[dd,'granted_count']\n",
    "#                 df_patsat.at[de,'granted_family_ge_2_count'] += df_patsat.at[dd,'granted_family_ge_2_count']\n",
    "#     df_patsat.drop(df_patsat[df_patsat['country'] == 'LI'].index, inplace=True)\n",
    "#     df_patsat.drop(df_patsat[df_patsat['country'] == 'VG'].index, inplace=True)\n",
    "#     df_patsat.drop(df_patsat[df_patsat['country'] == 'DD'].index, inplace=True)\n",
    "#     df_patsat.drop(df_patsat[df_patsat['country'] == 'FO'].index, inplace=True)\n",
    "#     df_patsat[\"total_deaths\"] = 0\n",
    "#     df_patsat[\"total_affected\"] = 0\n",
    "#     df_patsat[\"total_damages_adj\"] = 0\n",
    "#     for country in pd.unique(df_patsat.country):\n",
    "#         if country == 'DE' or country == 'CZ':\n",
    "#             emdat_countries = emdat_patsat_countries[country]\n",
    "#         else:\n",
    "#             emdat_countries = [emdat_patsat_countries[country]]\n",
    "        \n",
    "#         for ec in emdat_countries:\n",
    "#             for year in range( 1985,  2020 + 1):\n",
    "#                 pt_year = np.where((df_patsat['year'] == year) & (df_patsat['country'] == country))\n",
    "#                 if pt_year[0].size>0:\n",
    "#                     pt = pt_year[0][0]\n",
    "#                     em = np.where((df_emdat['year'] == year) & (df_emdat['country'] == ec) )[0][0]\n",
    "#                     df_patsat.at[pt,'total_deaths'] = df_emdat.at[em,'total_deaths']\n",
    "#                     df_patsat.at[pt,'total_affected'] =  df_emdat.at[em,'total_affected']\n",
    "#                     df_patsat.at[pt,'total_damages_adj'] = df_emdat.at[em,'total_damages_adj']\n",
    "#     if patsat=='1_ExTemp':\n",
    "#         print(pd.unique(df_patsat['country']))\n",
    "        \n",
    "#     print('Combined ' + patsat)    \n",
    "#     df_patsat.to_csv(patsat + '_panel_combined.csv', encoding='utf-8', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178e135",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for patsat, emdat in emdat_patsat_names.items():\n",
    "    df_patsat =  pd.read_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/' + patsat + '_panel.csv', skipinitialspace=True, header=0)\n",
    "    df_emdat = pd.read_csv(emdat + '_EMDAT_panel.csv', skipinitialspace=True, header=0)\n",
    "    if np.where(df_patsat['country'] == 'DD')[0].size>0:\n",
    "        for year in range( 1985,  2020 + 1):\n",
    "            dd_year = np.where((df_patsat['year'] == year) & (df_patsat['country'] == 'DD'))\n",
    "            if dd_year[0].size>0:\n",
    "                dd = dd_year[0][0]\n",
    "                de = np.where((df_patsat['year'] == year) & (df_patsat['country'] == 'DE') )[0][0]\n",
    "                df_patsat.at[de,'total_count'] += df_patsat.at[dd,'total_count']\n",
    "                df_patsat.at[de,'granted_count'] +=  df_patsat.at[dd,'granted_count']\n",
    "                df_patsat.at[de,'granted_family_ge_2_count'] += df_patsat.at[dd,'granted_family_ge_2_count']\n",
    "                df_patsat.at[de,'K_stock'] += df_patsat.at[dd,'K_stock']\n",
    "    df_patsat.drop(df_patsat[df_patsat['country'] == 'LI'].index, inplace=True)\n",
    "    df_patsat.drop(df_patsat[df_patsat['country'] == 'VG'].index, inplace=True)\n",
    "    df_patsat.drop(df_patsat[df_patsat['country'] == 'DD'].index, inplace=True)\n",
    "    df_patsat.drop(df_patsat[df_patsat['country'] == 'FO'].index, inplace=True)\n",
    "    df_emdat['country'] = df_emdat['country'].map(emdat_patsat_map).fillna(df_emdat['country'])\n",
    "    de_cz_emdat_list=[]\n",
    "\n",
    "    for year in range(1985,2020+1):\n",
    "        deaths = 0\n",
    "        damage = 0\n",
    "        affected = 0\n",
    "        for country in ['DE0','DE1','DE2']:\n",
    "            deaths += df_emdat[(df_emdat['country']==country) & (df_emdat['year']==year)]['total_deaths'].to_numpy()[0]\n",
    "            damage += df_emdat[(df_emdat['country']==country) & (df_emdat['year']==year)]['total_damages_adj'].to_numpy()[0]\n",
    "            affected += df_emdat[(df_emdat['country']==country) & (df_emdat['year']==year)]['total_affected'].to_numpy()[0]\n",
    "        de_cz_emdat_list.append({'country':country[:2],'year':year,'total_deaths':deaths,'total_damages_adj':damage,'total_affected':affected})\n",
    "\n",
    "    for year in range(1985,2020+1):\n",
    "        deaths = 0\n",
    "        damage = 0\n",
    "        affected = 0\n",
    "        for country in ['CZ0','CZ1','CZ2']:\n",
    "            deaths += df_emdat[(df_emdat['country']==country) & (df_emdat['year']==year)]['total_deaths'].to_numpy()[0]\n",
    "            damage += df_emdat[(df_emdat['country']==country) & (df_emdat['year']==year)]['total_damages_adj'].to_numpy()[0]\n",
    "            affected += df_emdat[(df_emdat['country']==country) & (df_emdat['year']==year)]['total_affected'].to_numpy()[0]\n",
    "        de_cz_emdat_list.append({'country':country[:2],'year':year,'total_deaths':deaths,'total_damages_adj':damage,'total_affected':affected})\n",
    "\n",
    "    df_de_cz = pd.DataFrame.from_records(de_cz_emdat_list)\n",
    "    df_emdat = pd.concat([df_de_cz,df_emdat])\n",
    "    df_combined = df_patsat.merge(df_emdat,on=['country','year'], how='inner')\n",
    "    df_combined.to_csv(patsat + '_panel_combined.csv', encoding='utf-8', index=False)\n",
    "    print('Combined ' + patsat)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05977a53",
   "metadata": {},
   "source": [
    "### Combine green technologies PATSAT data with the combined data above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12984a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Categories = ['Build','Sequester', 'ICT', 'Geo', 'Hydro', 'Ocean', 'Solar-T', 'PV', 'Thermal-PV', 'Wind', 'Combust', 'Fusion', 'Fission', 'Electric', 'Biofuel', 'Waste', 'Store- B', 'Store - C', 'Store- T', 'Store- M', 'Hydrogen', 'Processing', 'Transport', 'Wastewater', 'SmrtGrds', 'Nuclear', 'Non-Fossil', 'Enable',  'Other-1', 'Other-3']#, 'Other-5','Other-6', 'Other-4']\n",
    "df_controls =pd.read_csv('controls_processed.csv', skipinitialspace=True, header=0)\n",
    "for category in Categories:\n",
    "    print(\"Now processing: \"+ category)\n",
    "    try:\n",
    "        df_cat = pd.read_csv('/Volumes/NJ_4TB/PATSAT/MyFiles/' + category + '_panel.csv', skipinitialspace=True, header=0)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        df_cat = pd.DataFrame()\n",
    "    if df_cat.empty:\n",
    "        print('Skipped '+ category)\n",
    "        continue\n",
    "    if np.where(df_cat['country'] == 'DD')[0].size>0:\n",
    "        for year in range( 1985,  2020 + 1):\n",
    "            dd_year = np.where((df_cat['year'] == year) & (df_cat['country'] == 'DD'))\n",
    "            if dd_year[0].size>0:\n",
    "                dd = dd_year[0][0]\n",
    "                de = np.where((df_cat['year'] == year) & (df_cat['country'] == 'DE') )[0][0]\n",
    "                df_cat.at[de,'total_count'] += df_cat.at[dd,'total_count']\n",
    "                df_cat.at[de,'granted_count'] +=  df_cat.at[dd,'granted_count']\n",
    "                df_cat.at[de,'granted_family_ge_2_count'] += df_cat.at[dd,'granted_family_ge_2_count']\n",
    "                df_cat.at[de,'K_stock'] += df_cat.at[dd,'K_stock']\n",
    "    df_cat.drop(df_cat[df_cat['country'] == 'LI'].index, inplace=True)\n",
    "    df_cat.drop(df_cat[df_cat['country'] == 'VG'].index, inplace=True)\n",
    "    df_cat.drop(df_cat[df_cat['country'] == 'DD'].index, inplace=True)\n",
    "    df_cat.drop(df_cat[df_cat['country'] == 'FO'].index, inplace=True)\n",
    "    df_cat = pd.concat([pd.get_dummies(df_cat['year']), df_cat],axis=1)\n",
    "    df_cat.loc[:, 'K_stock'] = np.log(1 + df_cat['K_stock'])\n",
    "    df_cat.rename(columns={'total_count':category+'_total_count', 'granted_count':category +'_granted_count', 'granted_family_ge_2_count':category+'_granted_family_ge_2_count', 'K_stock':category+'_K_stock'}, inplace=True)\n",
    "    df_cat = df_cat.merge(df_controls, on=['country','year'], how='left')#NaNs if controls are not present \n",
    "    for adaptive in emdat_patsat_names.keys():        \n",
    "        df_adapt = pd.read_csv(adaptive + '_panel_combined.csv', skipinitialspace=True, header=0)\n",
    "        df_adapt.loc[:, 'K_stock'] = np.log(1 + df_adapt['K_stock'])\n",
    "        df_adapt.rename(columns={'total_count':adaptive+'_total_count', 'granted_count':adaptive+'_granted_count', 'granted_family_ge_2_count':adaptive+'_granted_family_ge_2_count', 'K_stock':adaptive+'_K_stock'}, inplace=True)\n",
    "        df_final=df_cat.merge(df_adapt, on=['country','year'], how='inner')\n",
    "        df_final.loc[:, 'gdp_per_capita'] = np.log(df_final['gdp_per_capita'])\n",
    "        df_final.loc[:, 'control_total_patents'] = np.log(df_final['control_total_patents'])\n",
    "        df_final.drop(df_final[df_final['year'] >2018].index, inplace=True)\n",
    "        df_final.drop(labels =2019, axis =1, inplace=True, errors='ignore')\n",
    "        df_final.drop(labels =2020, axis =1, inplace=True, errors='ignore')\n",
    "        #  print('Combined ' + category + ' with '+ adaptive)    \n",
    "        directory = 'Adaptive_Mitigative/'# + category + '_' + adaptive + '/'\n",
    "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "        df_final.to_csv( directory + category + '_' + adaptive + '_panel_combined.csv', encoding='utf-8', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05249e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
